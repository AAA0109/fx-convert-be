# Generated by Django 3.2.8 on 2023-06-27 17:35
import numpy as np
import pandas as pd
from django.db import migrations


def remove_duplicated_dates_on_fxspot_eod(apps, schema_editor):
    DataCut = apps.get_model('marketdata', 'DataCut')
    FxSpot = apps.get_model('marketdata', 'FxSpot')

    datacut_df = pd.DataFrame(list(DataCut.objects.filter(cut_type=1).values())).rename(
        columns={"id": "data_cut_id"})
    fxspot_df = pd.DataFrame(list(FxSpot.objects.filter(data_cut__cut_type=1).values()))

    fxspot_cut_df = pd.merge(fxspot_df, datacut_df, on='data_cut_id', how='left').rename(columns={"id": "fxspot_id"})

    pair_ids = [i for i in range(1, 94)]
    for pair_id in pair_ids:
        fxspot_cut_pair_df = fxspot_cut_df[fxspot_cut_df['pair_id'] == pair_id].copy()
        if fxspot_cut_pair_df.empty:
            continue
        fxspot_cut_pair_df.reset_index(inplace=True, drop=True)
        # added columns required for selection
        fxspot_cut_pair_df = fxspot_cut_pair_df.copy()
        fxspot_cut_pair_df['hour'] = fxspot_cut_pair_df["cut_time"].dt.hour
        fxspot_cut_pair_df['date_group'] = fxspot_cut_pair_df["cut_time"].dt.date

        fxspot_cut_pair_df['is_rate_distance_close'] = fxspot_cut_pair_df.apply(
            lambda row: np.isclose(row['rate'], row['rate_bid'], rtol=1e-07, atol=1e-07)
                        and np.isclose(row['rate_bid'], row['rate_ask'], rtol=1e-07,
                                       atol=1e-07), axis=1)
        fxspot_cut_pair_df['is_rate_distance_close'] = fxspot_cut_pair_df['is_rate_distance_close'].astype(int)
        # Sort values
        df_sorted = fxspot_cut_pair_df.sort_values(['date_group', 'hour', 'is_rate_distance_close', 'fxspot_id'],
                                                   ascending=[True, False, False, False])
        if not df_sorted.index.is_unique:
            raise ValueError("Index is not unique")

        # Drop duplicates
        df_kept = df_sorted.drop_duplicates(subset=['date_group'], keep='first')

        df_removed = df_sorted.loc[~df_sorted.index.isin(df_kept.index)]
        if df_removed.empty:
            continue
        FxSpot.objects.filter(id__in=df_removed["fxspot_id"].tolist()).delete()


class Migration(migrations.Migration):
    dependencies = [
        ('marketdata', '0016_auto_20230623_0033'),
    ]

    operations = [
        migrations.RunPython(remove_duplicated_dates_on_fxspot_eod)
    ]
